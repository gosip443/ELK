[toc]

# ELK 架构介绍

## 1. 概述

`ELK` 是一个应用套件，由 `Elasticsearch`、`Logstash`、`Kibana` 三部分组件构成，简称 `ELK` ，它是一套开源免费、功能强大的日志分析管理系统。`ELK` 可以将系统日志、网络日志、应用日志等各种日志进行收集、过滤、清洗，然后进行集中存放并且可用于实时检索、分析、展示。

这三款软件都是开源软件，通常是配合使用，而且又先后归于 Elastic.co 公司名下，故又被称为ELK Stack。下图是 ELK Stack 的基础组成。

![项目计划](images/2.ELK%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D.assets/1.png.jpg)

## 2. 核心构成

### 2.1 Elasticsearch 介绍

Elasticsearch 是一个实时的分布式搜索和分析引擎，它可以用于全文搜索，结构化搜索以及分析，采用java语言开发。

- 实时搜索，实时分析
- 分布式架构，实时文件存储，并将每一个字段都编入索引
- 文档导向，所有对象都是文档
- 高可用性，易扩展，支持集群（Cluster）、分片和复制（Shards 和 REplicas）
- 接口友好，支持 json

**ES架构**

Elasticsearch 支持集群架构，典型的集群架构如下：

<img src="images/2.ELK%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D.assets/es%E9%9B%86%E7%BE%A4.png" alt="es集群" style="zoom:67%;" />

从上图可以看出，Elasticsearch 集群中有 Master Node 和 Slave Node 两种角色，Master主要用作节点的协调和调度，Slave 是存储数据的节点，还有一种角色 CLient Node。

### 2.2 Logstash介绍

Logstash 是一款轻量化的、开源的、日志收集处理框架，它可以方便的把分散的、多样化的日志收集起来，并自定义过滤分析处理，然后传输到指定的位置，比如某个服务器或文件，Logstash 采用 JRuby 语言编写。

**Logstash 的理念很简单，从功能上讲，它只做三件事**

- input：数据收集
- filter：数据加工（如过滤、改写）
- output：数据输出

<img src="images/2.ELK%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D.assets/logstash.png" alt="logstash" style="zoom: 80%;" />

其中每个部分含义如下：

- Shipper：主要用于收集日志数据，负责监控本地日志文件的变化，及时把日志文件的最新内容收集起来，然后经过加工、过滤、输出到 Broker
- Broker：相当与日志 Hub，用来连接多个 Shipper 和多个 Indexer
- Indexer：从 Broker 读取文本，经过加工、过滤、输出到指定的介质（可以是文件、网络、ES等）中。Redis 服务器是 Logstash 官方推荐的 Broker ，这个 Broker 起到数据缓存的作用，通过这个缓存服务可以提高 Logstash Shipper 发送日志到 Logstash Indexer 的速度，同时避免各种原因导致的数据丢失。可以实现 Broker 功能的软件有很多，例如 Kafka。 

**说明**

这里需要说明的是，在实际应用中，Logstash 自身并没有什么角色，只是根据不用的功能、不同的配置给出不同的称呼而已，无论是 Shipper 还是 Indexer，始终只做前面提到的三件事。

重点掌握的是 Logstash 中 Shipper 和 Indexer 的作用，这两个部分是 Logstash 的核心功能。

### 2.3 Kibana 介绍

Kibana 是一个开源的数据分析可视化平台。使用 Kibana 可以将 Logstash 和 Elasticsearch 提供的日志数据进行高效的搜索、可视化汇总和多维分析，还可以与 Elasticsearch 搜索引擎之中的数据进行交互，它基于浏览器的界面可以快速创建动态仪表盘，实时监控 Elasticsearch 的数据状态与更改。

## 3. ELk 工作流程

一般都是在需要收集日志的所有服务器上部署 Logstash，作为 Logstash Shipper 用于监控并收集、过滤日志，接着将过滤后的数据发送给 Broker，然后 Logstash Indexer 将存放在 Broker 中的数据再写入 ELasticsearch，Elasticsearch 对这些数据创建索引，最后由 Kibaba 进行各种分析并以图标的形式展示。

<img src="images/2.ELK%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D.assets/ELK%E6%A6%82%E8%BF%B0.png" alt="ELK概述" style="zoom: 80%;" />

有些时候，如果收集的日志比较大，为了保证日志收集的性能和数据的完整性，Logstash Shipper 和 Logshatsh Indexer 之间的缓存器（Broker）也经常用 Kafka 来实现。

上图中，要重点掌握的是 **ELK 架构数据的流向**，以及 Logstash、Elasticsearch 和 Kibana **组合实现功能的细节**。

虽然官方推荐的Logstash Broker 是 Redis，但由于 Redis 无法对数据进行存储，故选择 Kafka 用作 Broker。